{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dFQZzbWkG2NM"
      },
      "source": [
        "## 依赖安装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qIOu0O6aEce"
      },
      "outputs": [],
      "source": [
        "!pip install python-dotenv\n",
        "!pip install openai"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kSKOhmvbOb3d"
      },
      "source": [
        "## 设置 OpenAI Key 环境变量"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vepw1ybUDdb"
      },
      "source": [
        "下面的 openai key 已脱敏处理，需要输入你自己的 openai key。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZoFdTo3OHJW",
        "outputId": "018eb8cc-bcf5-4d96-9efd-524450274b84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: OPENAI_API_KEY=sk-OWDAUVJgZKKRyNVUKWN9T3Bl====xbZP7XC0\n"
          ]
        }
      ],
      "source": [
        "%env OPENAI_API_KEY=sk-OWDAUVJgZKKRyNVUKWN9T3Bl====xbZP7XC0"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xsxx_5RLG-lR"
      },
      "source": [
        "## 获取 OpenAI Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "szH0x3_7ZJut"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ4ZW-tnHD-T"
      },
      "source": [
        "## 封装函数 prompt -> response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4PTIX-YbG1Ei"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0,\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ka8kny0eLhrM",
        "outputId": "f08b6fa7-c1ec-4757-a4a6-2ef013b1745b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'As an AI language model, I can tell you that the answer to 1+1 is 2.'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_completion('what is 1+1?')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gvaaQYy9PLrU"
      },
      "source": [
        "## Chat API: OpenAI"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XgZvVbyNUSwZ"
      },
      "source": [
        "下面是不使用 LangChain 的方式，利用 gpt 将文本翻译为目标语言。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kHrDVxL5RdT1"
      },
      "outputs": [],
      "source": [
        "origin_text = \"\"\"\n",
        "我会发着呆，然后微微笑，接着闭上眼。\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "N7kg8sJeSZ4b"
      },
      "outputs": [],
      "source": [
        "target_language = \"English\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DD3PzcmLSbzg",
        "outputId": "b65dc4c3-4081-4ef9-918b-d223c22f06c6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nPlease help me translate the following text into English.\\n\\n```\\n\\n我会发着呆，然后微微笑，接着闭上眼。\\n\\n```\\n\\nYou only need to output the translated result.\\n'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Please help me translate the following text into {target_language}.\n",
        "\n",
        "```\n",
        "{origin_text}\n",
        "```\n",
        "\n",
        "You only need to output the translated response.\n",
        "\"\"\"\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bt7d1RpoTt1G",
        "outputId": "97eb24ff-143d-4067-93b3-c1f9baf9fa9d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"I will stare blankly, then smile slightly, and then close my eyes.\"'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = get_completion(prompt)\n",
        "response"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yq9C42iuU1eR"
      },
      "source": [
        "## Chat API: LangChain"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "l5HCdYUiU35f"
      },
      "source": [
        "下面是通过 LangChain 的方式实现上面的例子。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVbQcBKSVtmy"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade langchain"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a5wdgOgRWobj"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "16j_Fog6Wql2"
      },
      "source": [
        "LangChain 对 ChatGPT API 进行了封装。temperature 参数默认为 0.7，其取值越大输出结果的随机性和创造性（瞎编）会越高，所以在这里我们设置为 0.0。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtesVo0eWcdX",
        "outputId": "de540b49-f743-47df-c7e3-434816219258"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatOpenAI(verbose=False, callbacks=None, callback_manager=None, tags=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# To control the randomness and creativity of the generated\n",
        "# text by an LLM, use temperature = 0.0\n",
        "chat = ChatOpenAI(temperature=0.0)\n",
        "chat"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cMq2FPYDZca8"
      },
      "source": [
        "根据上面输出的内容，可以知道调用 ChatOpenAI 构造函数创建了一个 model 对象，可以知道默认使用的是 gpt-3.5-turbo 模型和temperature 参数，以及你绑定的 openai key，还有其他参数目前还用不着。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mpL1jKuBX7B9"
      },
      "source": [
        "### Prompt template"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UHwmtalDaXgo"
      },
      "source": [
        "概念区分：\n",
        "\n",
        "- prompt： 一般作为可复用的模版，里面可以插入变量\n",
        "- message：最终输入给 ChatGPT 的问题，message = prompt + variables\n",
        "\n",
        "LangChain 提供了对 Prompt 更方便的操作方式：\n",
        "\n",
        "1. 用字符串定义一段 prompt，字符串中的 `{}` 是待插入的变量；\n",
        "2. 使用 `ChatPromptTemplate.from_template` 工厂函数传入该字符串格式的 prompt 作为参数，创建 prompt_template 对象；\n",
        "3. 利用该对象，可以访问到 prompt 中的变量命名，以及 prompt 的模版源字符串；\n",
        "4. 调用该对象上的 `format_messages` 传入变量，即可生成一个 messages list；\n",
        "5. 使用之前创建的 model 对象，即 chat，传入 messages，最终返回结果。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "9YUtlH0kYDOO"
      },
      "outputs": [],
      "source": [
        "prompt_template_string = \"\"\"\n",
        "Please help me translate the following text into {language}.\n",
        "\n",
        "```\n",
        "{text}\n",
        "```\n",
        "\n",
        "You only need to output the translated response.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHJ5T55lYXmv",
        "outputId": "ba99604b-9544-40bc-fbcb-36f1b2b48efa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['text', 'language'], output_parser=None, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language', 'text'], output_parser=None, partial_variables={}, template='\\nPlease help me translate the following text into {language}.\\n\\n```\\n{text}\\n```\\n\\nYou only need to output the translated result.\\n', template_format='f-string', validate_template=True), additional_kwargs={})])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(prompt_template_string)\n",
        "prompt_template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qAg5Szucgpy",
        "outputId": "6752f82d-8728-4e01-8051-d23c63d0ed34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['language', 'text'], output_parser=None, partial_variables={}, template='\\nPlease help me translate the following text into {language}.\\n\\n```\\n{text}\\n```\\n\\nYou only need to output the translated result.\\n', template_format='f-string', validate_template=True)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_template.messages[0].prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJPXYqOWcmFX",
        "outputId": "bbb60f96-be4d-4b8e-b324-9c15b343b5fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['language', 'text']"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_template.messages[0].prompt.input_variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVT7LhfvhJJ1",
        "outputId": "98c43ceb-2ec0-483a-a7ac-d77baa4e412e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='\\nPlease help me translate the following text into English.\\n\\n```\\n\\n我会发着呆，然后微微笑，接着闭上眼。\\n\\n```\\n\\nYou only need to output the translated result.\\n' additional_kwargs={} example=False\n"
          ]
        }
      ],
      "source": [
        "origin_text = \"\"\"\n",
        "我会发着呆，然后微微笑，接着闭上眼。\n",
        "\"\"\"\n",
        "target_language = \"English\"\n",
        "\n",
        "messages = prompt_template.format_messages(text = origin_text, language = target_language)\n",
        "print(messages[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8XrOrtyjAns",
        "outputId": "8322fb20-c557-40cb-cbd0-c518714a6f59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"I will stare blankly, then smile slightly, and then close my eyes.\"\n"
          ]
        }
      ],
      "source": [
        "response = chat(messages)\n",
        "print(response.content)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gLwtV227l6Ce"
      },
      "source": [
        "如果我们想将内容翻译为法语，只需要修改 `target_language` 为 `French`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ty0DxGQUmSGu",
        "outputId": "bdd0f30a-3fd5-4689-c3a7-95b3a586d2c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Je vais rester là à ne rien faire, puis sourire légèrement, puis fermer les yeux.\n"
          ]
        }
      ],
      "source": [
        "origin_text = \"\"\"\n",
        "我会发着呆，然后微微笑，接着闭上眼。\n",
        "\"\"\"\n",
        "target_language = \"French\"\n",
        "\n",
        "messages = prompt_template.format_messages(text = origin_text, language = target_language)\n",
        "response = chat(messages)\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uSO0m4s9vQPu"
      },
      "source": [
        "### Output Parsers"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vXdGV1OVvnRP"
      },
      "source": [
        "parsers 的作用是对 gpt 返回的内容解析为你所需要的格式。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0QrGXf8LwN1L"
      },
      "source": [
        "下面是希望 gpt 输出的格式，即调用 `chat(messages).content` 希望返回一个 Python 中的 Dictionary 数据类型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N7jaufZwR_M",
        "outputId": "a6eb7b83-d2a9-4c2b-e7df-e219d2dc71a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'gift': False, 'delivery_days': 5, 'price_value': 'pretty affordable!'}"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "{\n",
        "  \"gift\": False,\n",
        "  \"delivery_days\": 5,\n",
        "  \"price_value\": [\"pretty affordable!\"]\n",
        "}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "X_kJ0eiwP8fe"
      },
      "source": [
        "在不使用 parsers 的情况下，我们只能做到如下程度。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "m1ixUnlWLM83"
      },
      "outputs": [],
      "source": [
        "# 这是一段顾客的评论\n",
        "customer_review = \"\"\"\\\n",
        "这个吹叶机真的很不错，有四档风力：蜡烛吹、轻柔微风、狂风暴雨和龙卷风。\\\n",
        "它两天内就到了，正好赶上我给妻子的周年纪念礼物。\\\n",
        "我觉得我妻子非常喜欢它，甚至被它惊艳到了。\\\n",
        "目前我是唯一使用它的人，我一直在每隔一天早上使用它来清理我们草坪上的落叶。\\\n",
        "虽然它比其他吹叶机略贵一些，但我认为它的额外功能很值得购买。\n",
        "\"\"\"\n",
        "\n",
        "# 创建 template 字符串，让 gpt 分析评论，转换为 json 格式\n",
        "review_to_json_prompt_template_string = \"\"\"\\\n",
        "For the following text, extract the following information:\n",
        "\n",
        "gift: Was the item purchased as a gift for someone else? \\\n",
        "Answer True if yes, False if not or unknown.\n",
        "\n",
        "delivery_days: How many days did it take for the product \\\n",
        "to arrive? If this information is not found, output -1.\n",
        "\n",
        "price_value: Extract any sentences about the value or price,\\\n",
        "and output them as a comma separated Python list.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "gift\n",
        "delivery_days\n",
        "price_value\n",
        "\n",
        "text: {text}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJnJg3vUMC15",
        "outputId": "19c912fe-410e-4130-c027-bbcc3a25b162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"gift\": true,\n",
            "    \"delivery_days\": 2,\n",
            "    \"price_value\": [\"虽然它比其他吹叶机略贵一些，但我认为它的额外功能很值得购买。\"]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "reivew_to_json_prompt_template = ChatPromptTemplate.from_template(review_to_json_prompt_template_string)\n",
        "review_to_json_messages = reivew_to_json_prompt_template.format_messages(text = customer_review)\n",
        "\n",
        "response = chat(review_to_json_messages)\n",
        "print(response.content)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uuKzhBgiQJzN"
      },
      "source": [
        "这里的 `response.content` 实际上还是一个字符串，并不是我们所期待的 Dictionary 类型。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CmPFL1IYQTM2"
      },
      "source": [
        "下面会借助 parsers 的能力实现这个效果。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "yPWPAn_fQf_h"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import ResponseSchema\n",
        "from langchain.output_parsers import StructuredOutputParser"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GdYT-x6DSitq"
      },
      "source": [
        "以此定义每一个 json shcema 的 key，以及对其具体的描述。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "MSxQ9hBbRIVQ"
      },
      "outputs": [],
      "source": [
        "gift_schema = ResponseSchema(name=\"gift\", description=\"Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\")\n",
        "delivery_days_schema = ResponseSchema(name=\"delivery_days\", description=\"How many days did it take for the product to arrive? If this information is not found, output -1.\")\n",
        "price_value_schema = ResponseSchema(name=\"price_value\", description=\"Extract any sentences about the value or price, and output them as a comma separated Python list.\")\n",
        "\n",
        "response_schemas = [gift_schema, delivery_days_schema, price_value_schema] # 存放到 list 中"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7cU68QmbS9f5"
      },
      "source": [
        "使用 `StructuredOutputParser.from_response_schemas` 接收 `response_schemas` 创建 parser。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL-MLEFdSzEZ",
        "outputId": "869adbb0-6fef-4427-f187-a229614e990f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"gift\": string  // Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
            "\t\"delivery_days\": string  // How many days did it take for the product to arrive? If this information is not found, output -1.\n",
            "\t\"price_value\": string  // Extract any sentences about the value or price, and output them as a comma separated Python list.\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
        "response_format_instructions = output_parser.get_format_instructions()\n",
        "\n",
        "print(response_format_instructions) # 获取 parser 的提示语"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MFTuWD3BV24v"
      },
      "source": [
        "由于 parser 已经帮我们生成了格式化相关的 prompt，所以需要修改一下 template_string："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBHMrAYiWNHa",
        "outputId": "4a222ff9-84f9-45f5-a9ed-7e6b7195ac87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "{\n",
            "\t\"gift\": true,\n",
            "\t\"delivery_days\": \"2\",\n",
            "\t\"price_value\": [\"虽然它比其他吹叶机略贵一些，但我认为它的额外功能很值得购买。\"]\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "# 这是一段顾客的评论\n",
        "customer_review = \"\"\"\\\n",
        "这个吹叶机真的很不错，有四档风力：蜡烛吹、轻柔微风、狂风暴雨和龙卷风。\\\n",
        "它两天内就到了，正好赶上我给妻子的周年纪念礼物。\\\n",
        "我觉得我妻子非常喜欢它，甚至被它惊艳到了。\\\n",
        "目前我是唯一使用它的人，我一直在每隔一天早上使用它来清理我们草坪上的落叶。\\\n",
        "虽然它比其他吹叶机略贵一些，但我认为它的额外功能很值得购买。\n",
        "\"\"\"\n",
        "\n",
        "# 将 response_format_instructions 插入到 template_string 后面\n",
        "review_to_json_prompt_template_string = \"\"\"\\\n",
        "For the following text, extract the following information:\n",
        "\n",
        "gift: Was the item purchased as a gift for someone else? \\\n",
        "Answer True if yes, False if not or unknown.\n",
        "\n",
        "delivery_days: How many days did it take for the product \\\n",
        "to arrive? If this information is not found, output -1.\n",
        "\n",
        "price_value: Extract any sentences about the value or price,\\\n",
        "and output them as a comma separated Python list.\n",
        "\n",
        "text: {text}\n",
        "\n",
        "{format_instructions}\n",
        "\"\"\"\n",
        "\n",
        "reivew_to_json_prompt_template = ChatPromptTemplate.from_template(review_to_json_prompt_template_string)\n",
        "review_to_json_messages = reivew_to_json_prompt_template.format_messages(text = customer_review, format_instructions = response_format_instructions)\n",
        "\n",
        "response = chat(review_to_json_messages)\n",
        "print(response.content)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "j2dHjAfVZIQT"
      },
      "source": [
        "下面还需要借助 parser 来解析 `response.content`，将其转换为 Dictionary："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yk8QK2dVZS8R",
        "outputId": "3d8857a0-0216-4f9c-837e-af0588b3e9b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'gift': True, 'delivery_days': '2', 'price_value': ['虽然它比其他吹叶机略贵一些，但我认为它的额外功能很值得购买。']}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_dict = output_parser.parse(response.content)\n",
        "\n",
        "print(output_dict)\n",
        "type(output_dict)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
