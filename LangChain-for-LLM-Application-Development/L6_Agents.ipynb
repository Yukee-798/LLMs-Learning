{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1Iz4m1j4NPKLqA9JmRjm77Y2AWYwc3YVs","authorship_tag":"ABX9TyMisOufL4P+s+3WLVrAa7MC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# LangChain: Agents"],"metadata":{"id":"QBNAf7LXejLk"}},{"cell_type":"markdown","source":["把 LLM 当作推理引擎，给它提供文本或者其他信息来源，LLM 可能会使用它从互联网上学习的这些背景知识，也会利用你提供的新信息来帮助你回答问题，或者推理内容，甚至决定接下来要做什么。\n","\n","LangChain Agents 可以帮助你做这样的事情。"],"metadata":{"id":"wIXhVW_ah50U"}},{"cell_type":"markdown","source":["## 环境初始化"],"metadata":{"id":"MM-Rozkyeh8F"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"s6aWg_1T2zul"},"outputs":[],"source":["!pip install python-dotenv\n","!pip install openai\n","!pip install --upgrade langchain\n","!pip install -U wikipedia"]},{"cell_type":"code","source":["%env OPENAI_API_KEY=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"],"metadata":{"id":"Qs-jHxP0jdra"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import openai\n","\n","from dotenv import load_dotenv, find_dotenv\n","_ = load_dotenv(find_dotenv()) # read local .env file\n","openai.api_key = os.environ['OPENAI_API_KEY']"],"metadata":{"id":"AVZksXrAjf4W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 使用 Agents 进行数学运算和维基百科搜索"],"metadata":{"id":"uHTmfLB4fY9B"}},{"cell_type":"code","source":["from langchain.agents.agent_toolkits import create_python_agent\n","from langchain.agents import load_tools, initialize_agent\n","from langchain.agents import AgentType\n","from langchain.tools.python.tool import PythonREPLTool\n","from langchain.python import PythonREPL\n","from langchain.chat_models import ChatOpenAI\n","import langchain"],"metadata":{"id":"bO_bSGWAjodB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["langchain.debug = False\n","llm = ChatOpenAI(temperature=0) # 让推理结果尽可能准确严谨，设置 tem=0"],"metadata":{"id":"-GpTdyiok7SD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# llm-math 是一个结合了 llm 和 calculator 的 chain，用于解决数学问题\n","# wikipedia 是链接到维基百科的 API，允许查询维基百科的内容并返回搜索结果\n","tools = load_tools([\"llm-math\", \"wikipedia\"], llm=llm)"],"metadata":{"id":"jnaQ3ndXk8re"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 初始化 agent\n","agent = initialize_agent(\n","    tools,\n","    llm,\n","    # 注意 CHAT 和 REACT\n","    # CHAT 表示为 chat model 一起工作而优化\n","    # REACT 表示使用的一种 ReAct Prompting 方式 https://www.promptingguide.ai/techniques/react\n","    # 能让 llm 的推理效果更好\n","    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n","    # 当遇到 llm response 的内容无法被正常解析时，将格式错误的内容重新传回 llm，要求它自行纠正\n","    handle_parsing_errors=True,\n","    verbose=True\n",")"],"metadata":{"id":"6VThGpL1k-Qp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["agent(\"What is the 25% of 300?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AZ0Wpu0Ok_Xc","executionInfo":{"status":"ok","timestamp":1687685212930,"user_tz":-480,"elapsed":5821,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}},"outputId":"3d5b6ab4-7ae6-42bd-c25e-3d871a1d2da1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new  chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mThought: We need to calculate 25% of 300, which involves multiplication and division.\n","\n","Action:\n","```\n","{\n","  \"action\": \"Calculator\",\n","  \"action_input\": \"300*0.25\"\n","}\n","```\n","\n","\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3mAnswer: 75.0\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3mWe have the answer to the question.\n","\n","Final Answer: 75.0\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input': 'What is the 25% of 300?', 'output': '75.0'}"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["执行 agent 后，会基于 ReAct Prompting，以 Thought, Action, Observation 的思维方式来解决问题。\n","\n","- `Though`t: 思考需要解决什么问题\n","- `Action` 表示具体操作，这里是一个 JSON 对象，action key 表示使用的工具，action_input key 表示该工具的输入\n","- `Observation`: 用于本次 Action 的结果观察，\"Answer: 75.0\" 为 Action 的返回结果\n","\n","下面会继续根据上一次 Thought 的结果进行思考，发现得到了问题的答案，那么最终确认答案为 \"75.0\"。"],"metadata":{"id":"c5E-d92C4nYn"}},{"cell_type":"markdown","source":["下面会使用 wikipedia 工具来解决问题。"],"metadata":{"id":"kdGdko1THUmy"}},{"cell_type":"code","source":["question = \"详细介绍 Prompt engineering\"\n","result = agent(question)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v-l4OHjXC6qO","executionInfo":{"status":"ok","timestamp":1687689125416,"user_tz":-480,"elapsed":17805,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}},"outputId":"f3e84b31-e5b2-44b9-d889-76b458f182a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new  chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mQuestion: Can you provide a detailed introduction to Prompt engineering?\n","Thought: I'm not sure what Prompt engineering is, so I'll need to use Wikipedia to research it.\n","Action:\n","```\n","{\n","  \"action\": \"Wikipedia\",\n","  \"action_input\": \"Prompt engineering\"\n","}\n","```\n","\u001b[0m\n","Observation: \u001b[33;1m\u001b[1;3mPage: Prompt engineering\n","Summary: Prompt engineering is a concept in artificial intelligence, particularly natural language processing (NLP). In prompt engineering, the description of the task that the AI is supposed to accomplish is embedded in the input, e.g. as a question, instead of it being explicitly given. Prompt engineering typically works by converting one or more tasks to a prompt-based dataset and training a language model with what has been called \"prompt-based learning\" or just \"prompt learning\".\n","\n","Page: In-context learning (natural language processing)\n","Summary: In natural language processing, in-context learning, few-shot learning or few-shot prompting is a prompting technique that allows a model to process examples before attempting a task. The method was popularized after the advent of GPT-3 and is considered to be an emergent property of large language models when its scaling behavior contains greater than zero breaks.A few-shot prompt normally includes n examples of (problem, solution) pairs known as \"shots\", with the overall usage of such a prompt being known as n-shot prompting. For instance, the following is a one-shot prompt for review sentiment classification: Review: This movie sucks. Sentiment: negative. Review: I love this movie. Sentiment: If the model outputs \"positive\", then it has correctly solved the task.The term zero-shot prompting is often used to signify that no examples are provided. An example of a zero-shot prompt for a question-answering task would be \"Who wrote the book On the Origin of Species?\".\n","In-context learning was initially proposed as an alternative to fine-tuning a pre-trained language model on a task-specific dataset. Since no parameters are changed in the model, the model itself doesn't learn anything. But the prompt primes the model for subsequent inference, within a particular conversation or context.  The main advantages of in-context learning over fine-tuning are a reduction in the amount of task-specific data needed and a reduced potential of overfitting by learning an overly narrow distribution from a large but narrow fine-tuning dataset. Few-shot performance of large language models has been shown to achieve competitive results on NLP tasks, sometimes surpassing prior state-of-the-art fine-tuning approaches. Examples of such NLP tasks are translation, question answering, cloze tasks, unscrambling words, and using a novel word in a sentence. The creation and optimization of such few-shot prompts is part of the now active field of study of prompt engineering.While few-shot prompting has performed competitively when compared to fine-tuned models, it has its own drawbacks. For example, it has been shown that the order in which the shots are listed can make the difference between state-of-the-art and random guess performance. A set of few-shot examples that works well in some specific order with one model may not work at all when used with a different model. Despite these shortcomings, the commonly used Transformer model can encode principled learning algorithms based on gradient descent inside their weights and enable mesa-optimization i.e. learn-to-learn small models based on the data given in-context when making predictions.A common example of in-context learning is chain-of-thought prompting, where few-shot examples are given to teach the model to output a string of reasoning before attempting to answer a question. This technique has been shown to improve performance of models in tasks that require logical thinking and reasoning.\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3mBased on the Wikipedia page, Prompt engineering is a concept in artificial intelligence, particularly natural language processing, where the description of the task that the AI is supposed to accomplish is embedded in the input, e.g. as a question, instead of it being explicitly given. This is done by converting one or more tasks to a prompt-based dataset and training a language model with what has been called \"prompt-based learning\" or just \"prompt learning\". In-context learning is a related concept that allows a model to process examples before attempting a task, and it has been shown to achieve competitive results on NLP tasks. The creation and optimization of such few-shot prompts is part of the now active field of study of prompt engineering. \n","Action:\n","```\n","{\n","  \"action\": \"None\",\n","  \"action_input\": \"\"\n","}\n","```\n","\u001b[0m\n","Observation: None is not a valid tool, try another one.\n","Thought:\u001b[32;1m\u001b[1;3mI don't need to use any tool for this question, as I have already found the information I need from Wikipedia.\n","Final Answer: Prompt engineering is a concept in artificial intelligence, particularly natural language processing, where the description of the task that the AI is supposed to accomplish is embedded in the input, e.g. as a question, instead of it being explicitly given. This is done by converting one or more tasks to a prompt-based dataset and training a language model with what has been called \"prompt-based learning\" or just \"prompt learning\". In-context learning is a related concept that allows a model to process examples before attempting a task, and it has been shown to achieve competitive results on NLP tasks. The creation and optimization of such few-shot prompts is part of the now active field of study of prompt engineering.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]}]},{"cell_type":"markdown","source":["黄色的文本表示调用 wikipedia api 时找到的内容，绿色的文本表示调用 llm 时的 prompt。"],"metadata":{"id":"zW_LsmAxHkfK"}},{"cell_type":"code","source":["result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rA_PQwRsF4Ry","executionInfo":{"status":"ok","timestamp":1687689152970,"user_tz":-480,"elapsed":332,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}},"outputId":"8aa92b9b-5245-4fd9-aee8-f328aa4d80b7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input': '详细介绍 Prompt engineering',\n"," 'output': 'Prompt engineering is a concept in artificial intelligence, particularly natural language processing, where the description of the task that the AI is supposed to accomplish is embedded in the input, e.g. as a question, instead of it being explicitly given. This is done by converting one or more tasks to a prompt-based dataset and training a language model with what has been called \"prompt-based learning\" or just \"prompt learning\". In-context learning is a related concept that allows a model to process examples before attempting a task, and it has been shown to achieve competitive results on NLP tasks. The creation and optimization of such few-shot prompts is part of the now active field of study of prompt engineering.'}"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","source":["下面开启 debug，详细分析一下整个链路逻辑。"],"metadata":{"id":"8eCeQHtQIDgd"}},{"cell_type":"code","source":["langchain.debug = True\n","\n","question = \"详细介绍 Prompt engineering\"\n","result = agent(question)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YPQYGsKZH9An","executionInfo":{"status":"ok","timestamp":1687689525207,"user_tz":-480,"elapsed":19471,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}},"outputId":"1d921dbd-4f1d-4fab-c64e-872754da0a73"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n","\u001b[0m{\n","  \"input\": \"详细介绍 Prompt engineering\"\n","}\n","\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] Entering Chain run with input:\n","\u001b[0m{\n","  \"input\": \"详细介绍 Prompt engineering\",\n","  \"agent_scratchpad\": \"\",\n","  \"stop\": [\n","    \"Observation:\"\n","  ]\n","}\n","\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatOpenAI] Entering LLM run with input:\n","\u001b[0m{\n","  \"prompts\": [\n","    \"System: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \\\"action\\\" field are: Calculator, Wikipedia\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\\nHuman: 详细介绍 Prompt engineering\"\n","  ]\n","}\n","\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatOpenAI] [2.75s] Exiting LLM run with output:\n","\u001b[0m{\n","  \"generations\": [\n","    [\n","      {\n","        \"text\": \"Question: Can you provide a detailed introduction to Prompt engineering?\\nThought: I'm not sure what Prompt engineering is, so I'll need to use Wikipedia to research it.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Wikipedia\\\",\\n  \\\"action_input\\\": \\\"Prompt engineering\\\"\\n}\\n```\\n\",\n","        \"generation_info\": null,\n","        \"message\": {\n","          \"content\": \"Question: Can you provide a detailed introduction to Prompt engineering?\\nThought: I'm not sure what Prompt engineering is, so I'll need to use Wikipedia to research it.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Wikipedia\\\",\\n  \\\"action_input\\\": \\\"Prompt engineering\\\"\\n}\\n```\\n\",\n","          \"additional_kwargs\": {},\n","          \"example\": false\n","        }\n","      }\n","    ]\n","  ],\n","  \"llm_output\": {\n","    \"token_usage\": {\n","      \"prompt_tokens\": 316,\n","      \"completion_tokens\": 59,\n","      \"total_tokens\": 375\n","    },\n","    \"model_name\": \"gpt-3.5-turbo\"\n","  },\n","  \"run\": null\n","}\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] [2.76s] Exiting Chain run with output:\n","\u001b[0m{\n","  \"text\": \"Question: Can you provide a detailed introduction to Prompt engineering?\\nThought: I'm not sure what Prompt engineering is, so I'll need to use Wikipedia to research it.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Wikipedia\\\",\\n  \\\"action_input\\\": \\\"Prompt engineering\\\"\\n}\\n```\\n\"\n","}\n","\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:Wikipedia] Entering Tool run with input:\n","\u001b[0m\"Prompt engineering\"\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n","\n","The code that caused this warning is on line 389 of the file /usr/local/lib/python3.10/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n","\n","  lis = BeautifulSoup(html).find_all('li')\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:Wikipedia] [1.30s] Exiting Tool run with output:\n","\u001b[0m\"Page: Prompt engineering\n","Summary: Prompt engineering is a concept in artificial intelligence, particularly natural language processing (NLP). In prompt engineering, the description of the task that the AI is supposed to accomplish is embedded in the input, e.g. as a question, instead of it being explicitly given. Prompt engineering typically works by converting one or more tasks to a prompt-based dataset and training a language model with what has been called \"prompt-based learning\" or just \"prompt learning\".\n","\n","Page: In-context learning (natural language processing)\n","Summary: In natural language processing, in-context learning, few-shot learning or few-shot prompting is a prompting technique that allows a model to process examples before attempting a task. The method was popularized after the advent of GPT-3 and is considered to be an emergent property of large language models when its scaling behavior contains greater than zero breaks.A few-shot prompt normally includes n examples of (problem, solution) pairs known as \"shots\", with the overall usage of such a prompt being known as n-shot prompting. For instance, the following is a one-shot prompt for review sentiment classification: Review: This movie sucks. Sentiment: negative. Review: I love this movie. Sentiment: If the model outputs \"positive\", then it has correctly solved the task.The term zero-shot prompting is often used to signify that no examples are provided. An example of a zero-shot prompt for a question-answering task would be \"Who wrote the book On the Origin of Species?\".\n","In-context learning was initially proposed as an alternative to fine-tuning a pre-trained language model on a task-specific dataset. Since no parameters are changed in the model, the model itself doesn't learn anything. But the prompt primes the model for subsequent inference, within a particular conversation or context.  The main advantages of in-context learning over fine-tuning are a reduction in the amount of task-specific data needed and a reduced potential of overfitting by learning an overly narrow distribution from a large but narrow fine-tuning dataset. Few-shot performance of large language models has been shown to achieve competitive results on NLP tasks, sometimes surpassing prior state-of-the-art fine-tuning approaches. Examples of such NLP tasks are translation, question answering, cloze tasks, unscrambling words, and using a novel word in a sentence. The creation and optimization of such few-shot prompts is part of the now active field of study of prompt engineering.While few-shot prompting has performed competitively when compared to fine-tuned models, it has its own drawbacks. For example, it has been shown that the order in which the shots are listed can make the difference between state-of-the-art and random guess performance. A set of few-shot examples that works well in some specific order with one model may not work at all when used with a different model. Despite these shortcomings, the commonly used Transformer model can encode principled learning algorithms based on gradient descent inside their weights and enable mesa-optimization i.e. learn-to-learn small models based on the data given in-context when making predictions.A common example of in-context learning is chain-of-thought prompting, where few-shot examples are given to teach the model to output a string of reasoning before attempting to answer a question. This technique has been shown to improve performance of models in tasks that require logical thinking and reasoning.\"\n","\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 5:chain:LLMChain] Entering Chain run with input:\n","\u001b[0m{\n","  \"input\": \"详细介绍 Prompt engineering\",\n","  \"agent_scratchpad\": \"This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nQuestion: Can you provide a detailed introduction to Prompt engineering?\\nThought: I'm not sure what Prompt engineering is, so I'll need to use Wikipedia to research it.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Wikipedia\\\",\\n  \\\"action_input\\\": \\\"Prompt engineering\\\"\\n}\\n```\\n\\nObservation: Page: Prompt engineering\\nSummary: Prompt engineering is a concept in artificial intelligence, particularly natural language processing (NLP). In prompt engineering, the description of the task that the AI is supposed to accomplish is embedded in the input, e.g. as a question, instead of it being explicitly given. Prompt engineering typically works by converting one or more tasks to a prompt-based dataset and training a language model with what has been called \\\"prompt-based learning\\\" or just \\\"prompt learning\\\".\\n\\nPage: In-context learning (natural language processing)\\nSummary: In natural language processing, in-context learning, few-shot learning or few-shot prompting is a prompting technique that allows a model to process examples before attempting a task. The method was popularized after the advent of GPT-3 and is considered to be an emergent property of large language models when its scaling behavior contains greater than zero breaks.A few-shot prompt normally includes n examples of (problem, solution) pairs known as \\\"shots\\\", with the overall usage of such a prompt being known as n-shot prompting. For instance, the following is a one-shot prompt for review sentiment classification: Review: This movie sucks. Sentiment: negative. Review: I love this movie. Sentiment: If the model outputs \\\"positive\\\", then it has correctly solved the task.The term zero-shot prompting is often used to signify that no examples are provided. An example of a zero-shot prompt for a question-answering task would be \\\"Who wrote the book On the Origin of Species?\\\".\\nIn-context learning was initially proposed as an alternative to fine-tuning a pre-trained language model on a task-specific dataset. Since no parameters are changed in the model, the model itself doesn't learn anything. But the prompt primes the model for subsequent inference, within a particular conversation or context.  The main advantages of in-context learning over fine-tuning are a reduction in the amount of task-specific data needed and a reduced potential of overfitting by learning an overly narrow distribution from a large but narrow fine-tuning dataset. Few-shot performance of large language models has been shown to achieve competitive results on NLP tasks, sometimes surpassing prior state-of-the-art fine-tuning approaches. Examples of such NLP tasks are translation, question answering, cloze tasks, unscrambling words, and using a novel word in a sentence. The creation and optimization of such few-shot prompts is part of the now active field of study of prompt engineering.While few-shot prompting has performed competitively when compared to fine-tuned models, it has its own drawbacks. For example, it has been shown that the order in which the shots are listed can make the difference between state-of-the-art and random guess performance. A set of few-shot examples that works well in some specific order with one model may not work at all when used with a different model. Despite these shortcomings, the commonly used Transformer model can encode principled learning algorithms based on gradient descent inside their weights and enable mesa-optimization i.e. learn-to-learn small models based on the data given in-context when making predictions.A common example of in-context learning is chain-of-thought prompting, where few-shot examples are given to teach the model to output a string of reasoning before attempting to answer a question. This technique has been shown to improve performance of models in tasks that require logical thinking and reasoning.\\nThought:\",\n","  \"stop\": [\n","    \"Observation:\"\n","  ]\n","}\n","\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 5:chain:LLMChain > 6:llm:ChatOpenAI] Entering LLM run with input:\n","\u001b[0m{\n","  \"prompts\": [\n","    \"System: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \\\"action\\\" field are: Calculator, Wikipedia\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\\nHuman: 详细介绍 Prompt engineering\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nQuestion: Can you provide a detailed introduction to Prompt engineering?\\nThought: I'm not sure what Prompt engineering is, so I'll need to use Wikipedia to research it.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Wikipedia\\\",\\n  \\\"action_input\\\": \\\"Prompt engineering\\\"\\n}\\n```\\n\\nObservation: Page: Prompt engineering\\nSummary: Prompt engineering is a concept in artificial intelligence, particularly natural language processing (NLP). In prompt engineering, the description of the task that the AI is supposed to accomplish is embedded in the input, e.g. as a question, instead of it being explicitly given. Prompt engineering typically works by converting one or more tasks to a prompt-based dataset and training a language model with what has been called \\\"prompt-based learning\\\" or just \\\"prompt learning\\\".\\n\\nPage: In-context learning (natural language processing)\\nSummary: In natural language processing, in-context learning, few-shot learning or few-shot prompting is a prompting technique that allows a model to process examples before attempting a task. The method was popularized after the advent of GPT-3 and is considered to be an emergent property of large language models when its scaling behavior contains greater than zero breaks.A few-shot prompt normally includes n examples of (problem, solution) pairs known as \\\"shots\\\", with the overall usage of such a prompt being known as n-shot prompting. For instance, the following is a one-shot prompt for review sentiment classification: Review: This movie sucks. Sentiment: negative. Review: I love this movie. Sentiment: If the model outputs \\\"positive\\\", then it has correctly solved the task.The term zero-shot prompting is often used to signify that no examples are provided. An example of a zero-shot prompt for a question-answering task would be \\\"Who wrote the book On the Origin of Species?\\\".\\nIn-context learning was initially proposed as an alternative to fine-tuning a pre-trained language model on a task-specific dataset. Since no parameters are changed in the model, the model itself doesn't learn anything. But the prompt primes the model for subsequent inference, within a particular conversation or context.  The main advantages of in-context learning over fine-tuning are a reduction in the amount of task-specific data needed and a reduced potential of overfitting by learning an overly narrow distribution from a large but narrow fine-tuning dataset. Few-shot performance of large language models has been shown to achieve competitive results on NLP tasks, sometimes surpassing prior state-of-the-art fine-tuning approaches. Examples of such NLP tasks are translation, question answering, cloze tasks, unscrambling words, and using a novel word in a sentence. The creation and optimization of such few-shot prompts is part of the now active field of study of prompt engineering.While few-shot prompting has performed competitively when compared to fine-tuned models, it has its own drawbacks. For example, it has been shown that the order in which the shots are listed can make the difference between state-of-the-art and random guess performance. A set of few-shot examples that works well in some specific order with one model may not work at all when used with a different model. Despite these shortcomings, the commonly used Transformer model can encode principled learning algorithms based on gradient descent inside their weights and enable mesa-optimization i.e. learn-to-learn small models based on the data given in-context when making predictions.A common example of in-context learning is chain-of-thought prompting, where few-shot examples are given to teach the model to output a string of reasoning before attempting to answer a question. This technique has been shown to improve performance of models in tasks that require logical thinking and reasoning.\\nThought:\"\n","  ]\n","}\n","\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 5:chain:LLMChain > 6:llm:ChatOpenAI] [7.48s] Exiting LLM run with output:\n","\u001b[0m{\n","  \"generations\": [\n","    [\n","      {\n","        \"text\": \"Based on the information I found on Wikipedia, prompt engineering is a concept in artificial intelligence, particularly natural language processing, where the description of the task that the AI is supposed to accomplish is embedded in the input, e.g. as a question, instead of it being explicitly given. This is typically done by converting one or more tasks to a prompt-based dataset and training a language model with what has been called \\\"prompt-based learning\\\" or just \\\"prompt learning\\\". In-context learning, few-shot learning, or few-shot prompting is a prompting technique that allows a model to process examples before attempting a task. This technique has been shown to improve performance of models in tasks that require logical thinking and reasoning. The creation and optimization of such few-shot prompts is part of the now active field of study of prompt engineering. \\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"None\\\"\\n}\\n```\\n\",\n","        \"generation_info\": null,\n","        \"message\": {\n","          \"content\": \"Based on the information I found on Wikipedia, prompt engineering is a concept in artificial intelligence, particularly natural language processing, where the description of the task that the AI is supposed to accomplish is embedded in the input, e.g. as a question, instead of it being explicitly given. This is typically done by converting one or more tasks to a prompt-based dataset and training a language model with what has been called \\\"prompt-based learning\\\" or just \\\"prompt learning\\\". In-context learning, few-shot learning, or few-shot prompting is a prompting technique that allows a model to process examples before attempting a task. This technique has been shown to improve performance of models in tasks that require logical thinking and reasoning. The creation and optimization of such few-shot prompts is part of the now active field of study of prompt engineering. \\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"None\\\"\\n}\\n```\\n\",\n","          \"additional_kwargs\": {},\n","          \"example\": false\n","        }\n","      }\n","    ]\n","  ],\n","  \"llm_output\": {\n","    \"token_usage\": {\n","      \"prompt_tokens\": 1082,\n","      \"completion_tokens\": 177,\n","      \"total_tokens\": 1259\n","    },\n","    \"model_name\": \"gpt-3.5-turbo\"\n","  },\n","  \"run\": null\n","}\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 5:chain:LLMChain] [7.48s] Exiting Chain run with output:\n","\u001b[0m{\n","  \"text\": \"Based on the information I found on Wikipedia, prompt engineering is a concept in artificial intelligence, particularly natural language processing, where the description of the task that the AI is supposed to accomplish is embedded in the input, e.g. as a question, instead of it being explicitly given. This is typically done by converting one or more tasks to a prompt-based dataset and training a language model with what has been called \\\"prompt-based learning\\\" or just \\\"prompt learning\\\". In-context learning, few-shot learning, or few-shot prompting is a prompting technique that allows a model to process examples before attempting a task. This technique has been shown to improve performance of models in tasks that require logical thinking and reasoning. The creation and optimization of such few-shot prompts is part of the now active field of study of prompt engineering. \\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"None\\\"\\n}\\n```\\n\"\n","}\n","\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 7:tool:_Exception] Entering Tool run with input:\n","\u001b[0m\"Invalid or incomplete response\"\n","\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 7:tool:_Exception] [0.13799999999999998ms] Exiting Tool run with output:\n","\u001b[0m\"Invalid or incomplete response\"\n","\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 8:chain:LLMChain] Entering Chain run with input:\n","\u001b[0m{\n","  \"input\": \"详细介绍 Prompt engineering\",\n","  \"agent_scratchpad\": \"This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nQuestion: Can you provide a detailed introduction to Prompt engineering?\\nThought: I'm not sure what Prompt engineering is, so I'll need to use Wikipedia to research it.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Wikipedia\\\",\\n  \\\"action_input\\\": \\\"Prompt engineering\\\"\\n}\\n```\\n\\nObservation: Page: Prompt engineering\\nSummary: Prompt engineering is a concept in artificial intelligence, particularly natural language processing (NLP). In prompt engineering, the description of the task that the AI is supposed to accomplish is embedded in the input, e.g. as a question, instead of it being explicitly given. Prompt engineering typically works by converting one or more tasks to a prompt-based dataset and training a language model with what has been called \\\"prompt-based learning\\\" or just \\\"prompt learning\\\".\\n\\nPage: In-context learning (natural language processing)\\nSummary: In natural language processing, in-context learning, few-shot learning or few-shot prompting is a prompting technique that allows a model to process examples before attempting a task. The method was popularized after the advent of GPT-3 and is considered to be an emergent property of large language models when its scaling behavior contains greater than zero breaks.A few-shot prompt normally includes n examples of (problem, solution) pairs known as \\\"shots\\\", with the overall usage of such a prompt being known as n-shot prompting. For instance, the following is a one-shot prompt for review sentiment classification: Review: This movie sucks. Sentiment: negative. Review: I love this movie. Sentiment: If the model outputs \\\"positive\\\", then it has correctly solved the task.The term zero-shot prompting is often used to signify that no examples are provided. An example of a zero-shot prompt for a question-answering task would be \\\"Who wrote the book On the Origin of Species?\\\".\\nIn-context learning was initially proposed as an alternative to fine-tuning a pre-trained language model on a task-specific dataset. Since no parameters are changed in the model, the model itself doesn't learn anything. But the prompt primes the model for subsequent inference, within a particular conversation or context.  The main advantages of in-context learning over fine-tuning are a reduction in the amount of task-specific data needed and a reduced potential of overfitting by learning an overly narrow distribution from a large but narrow fine-tuning dataset. Few-shot performance of large language models has been shown to achieve competitive results on NLP tasks, sometimes surpassing prior state-of-the-art fine-tuning approaches. Examples of such NLP tasks are translation, question answering, cloze tasks, unscrambling words, and using a novel word in a sentence. The creation and optimization of such few-shot prompts is part of the now active field of study of prompt engineering.While few-shot prompting has performed competitively when compared to fine-tuned models, it has its own drawbacks. For example, it has been shown that the order in which the shots are listed can make the difference between state-of-the-art and random guess performance. A set of few-shot examples that works well in some specific order with one model may not work at all when used with a different model. Despite these shortcomings, the commonly used Transformer model can encode principled learning algorithms based on gradient descent inside their weights and enable mesa-optimization i.e. learn-to-learn small models based on the data given in-context when making predictions.A common example of in-context learning is chain-of-thought prompting, where few-shot examples are given to teach the model to output a string of reasoning before attempting to answer a question. This technique has been shown to improve performance of models in tasks that require logical thinking and reasoning.\\nThought:Could not parse LLM output: Based on the information I found on Wikipedia, prompt engineering is a concept in artificial intelligence, particularly natural language processing, where the description of the task that the AI is supposed to accomplish is embedded in the input, e.g. as a question, instead of it being explicitly given. This is typically done by converting one or more tasks to a prompt-based dataset and training a language model with what has been called \\\"prompt-based learning\\\" or just \\\"prompt learning\\\". In-context learning, few-shot learning, or few-shot prompting is a prompting technique that allows a model to process examples before attempting a task. This technique has been shown to improve performance of models in tasks that require logical thinking and reasoning. The creation and optimization of such few-shot prompts is part of the now active field of study of prompt engineering. \\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"None\\\"\\n}\\n```\\n\\nObservation: Invalid or incomplete response\\nThought:\",\n","  \"stop\": [\n","    \"Observation:\"\n","  ]\n","}\n","\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 8:chain:LLMChain > 9:llm:ChatOpenAI] Entering LLM run with input:\n","\u001b[0m{\n","  \"prompts\": [\n","    \"System: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \\\"action\\\" field are: Calculator, Wikipedia\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\\nHuman: 详细介绍 Prompt engineering\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nQuestion: Can you provide a detailed introduction to Prompt engineering?\\nThought: I'm not sure what Prompt engineering is, so I'll need to use Wikipedia to research it.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Wikipedia\\\",\\n  \\\"action_input\\\": \\\"Prompt engineering\\\"\\n}\\n```\\n\\nObservation: Page: Prompt engineering\\nSummary: Prompt engineering is a concept in artificial intelligence, particularly natural language processing (NLP). In prompt engineering, the description of the task that the AI is supposed to accomplish is embedded in the input, e.g. as a question, instead of it being explicitly given. Prompt engineering typically works by converting one or more tasks to a prompt-based dataset and training a language model with what has been called \\\"prompt-based learning\\\" or just \\\"prompt learning\\\".\\n\\nPage: In-context learning (natural language processing)\\nSummary: In natural language processing, in-context learning, few-shot learning or few-shot prompting is a prompting technique that allows a model to process examples before attempting a task. The method was popularized after the advent of GPT-3 and is considered to be an emergent property of large language models when its scaling behavior contains greater than zero breaks.A few-shot prompt normally includes n examples of (problem, solution) pairs known as \\\"shots\\\", with the overall usage of such a prompt being known as n-shot prompting. For instance, the following is a one-shot prompt for review sentiment classification: Review: This movie sucks. Sentiment: negative. Review: I love this movie. Sentiment: If the model outputs \\\"positive\\\", then it has correctly solved the task.The term zero-shot prompting is often used to signify that no examples are provided. An example of a zero-shot prompt for a question-answering task would be \\\"Who wrote the book On the Origin of Species?\\\".\\nIn-context learning was initially proposed as an alternative to fine-tuning a pre-trained language model on a task-specific dataset. Since no parameters are changed in the model, the model itself doesn't learn anything. But the prompt primes the model for subsequent inference, within a particular conversation or context.  The main advantages of in-context learning over fine-tuning are a reduction in the amount of task-specific data needed and a reduced potential of overfitting by learning an overly narrow distribution from a large but narrow fine-tuning dataset. Few-shot performance of large language models has been shown to achieve competitive results on NLP tasks, sometimes surpassing prior state-of-the-art fine-tuning approaches. Examples of such NLP tasks are translation, question answering, cloze tasks, unscrambling words, and using a novel word in a sentence. The creation and optimization of such few-shot prompts is part of the now active field of study of prompt engineering.While few-shot prompting has performed competitively when compared to fine-tuned models, it has its own drawbacks. For example, it has been shown that the order in which the shots are listed can make the difference between state-of-the-art and random guess performance. A set of few-shot examples that works well in some specific order with one model may not work at all when used with a different model. Despite these shortcomings, the commonly used Transformer model can encode principled learning algorithms based on gradient descent inside their weights and enable mesa-optimization i.e. learn-to-learn small models based on the data given in-context when making predictions.A common example of in-context learning is chain-of-thought prompting, where few-shot examples are given to teach the model to output a string of reasoning before attempting to answer a question. This technique has been shown to improve performance of models in tasks that require logical thinking and reasoning.\\nThought:Could not parse LLM output: Based on the information I found on Wikipedia, prompt engineering is a concept in artificial intelligence, particularly natural language processing, where the description of the task that the AI is supposed to accomplish is embedded in the input, e.g. as a question, instead of it being explicitly given. This is typically done by converting one or more tasks to a prompt-based dataset and training a language model with what has been called \\\"prompt-based learning\\\" or just \\\"prompt learning\\\". In-context learning, few-shot learning, or few-shot prompting is a prompting technique that allows a model to process examples before attempting a task. This technique has been shown to improve performance of models in tasks that require logical thinking and reasoning. The creation and optimization of such few-shot prompts is part of the now active field of study of prompt engineering. \\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"None\\\"\\n}\\n```\\n\\nObservation: Invalid or incomplete response\\nThought:\"\n","  ]\n","}\n","\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 8:chain:LLMChain > 9:llm:ChatOpenAI] [7.46s] Exiting LLM run with output:\n","\u001b[0m{\n","  \"generations\": [\n","    [\n","      {\n","        \"text\": \"I don't need to take any further action since I have already provided a detailed introduction to Prompt engineering. \\nFinal Answer: Prompt engineering is a concept in artificial intelligence, particularly natural language processing, where the description of the task that the AI is supposed to accomplish is embedded in the input, e.g. as a question, instead of it being explicitly given. This is typically done by converting one or more tasks to a prompt-based dataset and training a language model with what has been called \\\"prompt-based learning\\\" or just \\\"prompt learning\\\". In-context learning, few-shot learning, or few-shot prompting is a prompting technique that allows a model to process examples before attempting a task. This technique has been shown to improve performance of models in tasks that require logical thinking and reasoning. The creation and optimization of such few-shot prompts is part of the now active field of study of prompt engineering.\",\n","        \"generation_info\": null,\n","        \"message\": {\n","          \"content\": \"I don't need to take any further action since I have already provided a detailed introduction to Prompt engineering. \\nFinal Answer: Prompt engineering is a concept in artificial intelligence, particularly natural language processing, where the description of the task that the AI is supposed to accomplish is embedded in the input, e.g. as a question, instead of it being explicitly given. This is typically done by converting one or more tasks to a prompt-based dataset and training a language model with what has been called \\\"prompt-based learning\\\" or just \\\"prompt learning\\\". In-context learning, few-shot learning, or few-shot prompting is a prompting technique that allows a model to process examples before attempting a task. This technique has been shown to improve performance of models in tasks that require logical thinking and reasoning. The creation and optimization of such few-shot prompts is part of the now active field of study of prompt engineering.\",\n","          \"additional_kwargs\": {},\n","          \"example\": false\n","        }\n","      }\n","    ]\n","  ],\n","  \"llm_output\": {\n","    \"token_usage\": {\n","      \"prompt_tokens\": 1276,\n","      \"completion_tokens\": 177,\n","      \"total_tokens\": 1453\n","    },\n","    \"model_name\": \"gpt-3.5-turbo\"\n","  },\n","  \"run\": null\n","}\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 8:chain:LLMChain] [7.46s] Exiting Chain run with output:\n","\u001b[0m{\n","  \"text\": \"I don't need to take any further action since I have already provided a detailed introduction to Prompt engineering. \\nFinal Answer: Prompt engineering is a concept in artificial intelligence, particularly natural language processing, where the description of the task that the AI is supposed to accomplish is embedded in the input, e.g. as a question, instead of it being explicitly given. This is typically done by converting one or more tasks to a prompt-based dataset and training a language model with what has been called \\\"prompt-based learning\\\" or just \\\"prompt learning\\\". In-context learning, few-shot learning, or few-shot prompting is a prompting technique that allows a model to process examples before attempting a task. This technique has been shown to improve performance of models in tasks that require logical thinking and reasoning. The creation and optimization of such few-shot prompts is part of the now active field of study of prompt engineering.\"\n","}\n","\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [19.01s] Exiting Chain run with output:\n","\u001b[0m{\n","  \"output\": \"Prompt engineering is a concept in artificial intelligence, particularly natural language processing, where the description of the task that the AI is supposed to accomplish is embedded in the input, e.g. as a question, instead of it being explicitly given. This is typically done by converting one or more tasks to a prompt-based dataset and training a language model with what has been called \\\"prompt-based learning\\\" or just \\\"prompt learning\\\". In-context learning, few-shot learning, or few-shot prompting is a prompting technique that allows a model to process examples before attempting a task. This technique has been shown to improve performance of models in tasks that require logical thinking and reasoning. The creation and optimization of such few-shot prompts is part of the now active field of study of prompt engineering.\"\n","}\n"]}]},{"cell_type":"markdown","source":["进入 `[1:chain:AgentExecutor]` 输入问题内容 \"详细介绍 Prompt engineering\"\n","\n","进入 `[1:chain:AgentExecutor > 2:chain:LLMChain]` 将下面内容作为输入：\n","\n","```json\n","{\n","  \"input\": \"详细介绍 Prompt engineering\",\n","  \"agent_scratchpad\": \"\",\n","  \"stop\": [\n","    \"Observation:\"\n","  ]\n","}\n","```\n","\n","- agent_scratchpad 的作用是让 agent 获取和存储信息\n","- stop 是一个字符串数组，告诉语言模型何时停止生成文本，遇到该字符串时就会停止\n","\n","进入 `[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatOpenAI]` 将下面内容作为输入：\n","\n","```json\n","{\n","  \"prompts\": [\n","    \"System: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \\\"action\\\" field are: Calculator, Wikipedia\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\\nHuman: 详细介绍 Prompt engineering\"\n","  ]\n","}\n","```\n","\n","这段 prompt 的要点如下：\n","\n","- 可用工具：告诉 ChatGPT 可以使用 `Calculator` 和 `Wikipedia` 这俩个工具，并且说明这俩个工具的作用。关于工具的描述的 prompt 是存在于 tool 内部的；\n","- 使用方法：指定一个 JSON Blob，包含 action 和 action_input 两个键，并且说明每个键的作用和约定，然后举例说明。不同的 Agent Type 会有不同的键；\n","- 答案格式要求：返回 ReAct Prompting 风格的内容，`Thought -> Action -> Observation` 可以一直重复下去，下一轮的 `Thought` 为上一轮的 `Observation`，直到得到 `Final Anser`。\n","  - `Question`: 来自用户输入的问题，只会出现一次；\n","  - `Thought`: 使用 LLM 思考如何解决问题，在这里会提及到使用哪些 Tools；\n","  - `Action`: 是一个 JSON 字符串，一般具有 \"action\" 和 \"action_input\" 俩个键，前者会携带一个 tool 的名称，后者表示使用 tool 时需要输入的数据；\n","  - `Observation`: 观察执行完 Action 后的结果，即 tool 返回的结果是啥，会判断该结果是否属于 `Final Anser`，即是否可以解决用户输入的 `Question`；\n","  - `Final Anser`: 经过一轮或多轮 ReAct Prompting 后得到可以解决用户 `Question` 的最终答案。\n","\n","\n","另外，值得注意的是这是一段 System Prompt，一般用于预定义一些参数和指令，帮助 AI 理解用户需要的输出、上下文以及响应格式，其具体作用如下：\n","\n","- 有针对性的响应：System Prompt 有助于缩小人工智能响应的范围，确保其紧扣主题并提供所需的信息；\n","- 提高准确性：通过提供清晰的说明和上下文，System Prompt 减少了 ChatGPT 生成不相关或不正确信息的几率；\n","- 定制化：开发人员可以定制 ChatGPT 的响应，以满足特定需求和应用程序。\n","\n","退出 `[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatOpenAI]` 输出如下内容：\n","\n","```json\n","{\n","  \"generations\": [\n","    [\n","      {\n","        \"text\": \"Question: Can you provide a detailed introduction to Prompt engineering?\\nThought: I'm not sure what Prompt engineering is, so I'll need to use Wikipedia to research it.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Wikipedia\\\",\\n  \\\"action_input\\\": \\\"Prompt engineering\\\"\\n}\\n```\\n\",\n","        \"generation_info\": null,\n","        \"message\": {\n","          \"content\": \"Question: Can you provide a detailed introduction to Prompt engineering?\\nThought: I'm not sure what Prompt engineering is, so I'll need to use Wikipedia to research it.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Wikipedia\\\",\\n  \\\"action_input\\\": \\\"Prompt engineering\\\"\\n}\\n```\\n\",\n","          \"additional_kwargs\": {},\n","          \"example\": false\n","        }\n","      }\n","    ]\n","  ],\n","  \"llm_output\": {\n","    \"token_usage\": {\n","      \"prompt_tokens\": 316,\n","      \"completion_tokens\": 59,\n","      \"total_tokens\": 375\n","    },\n","    \"model_name\": \"gpt-3.5-turbo\"\n","  },\n","  \"run\": null\n","}\n","```\n","\n","- `generations`: 记录了 LLM 生成的内容\n","- `llm_output`: 本次 QA 过程中 token 的使用情况，包含 prompt 与 response 都需要消耗 token\n","\n","将输出的内容格式化一下：\n","\n","```md\n","Question: Can you provide a detailed introduction to Prompt engineering?\n","\n","Thought: I'm not sure what Prompt engineering is, so I'll need to use Wikipedia to research it.\n","\n","Action:\n","{\n","  \"action\": \"Wikipedia\",\n","  \"action_input\": \"Prompt engineering\"\n","}\n","```\n","\n","退出 `[1:chain:AgentExecutor > 2:chain:LLMChain]` 输出下面内容：\n","\n","```json\n","{\n","  \"text\": \"Question: Can you provide a detailed introduction to Prompt engineering?\\nThought: I'm not sure what Prompt engineering is, so I'll need to use Wikipedia to research it.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Wikipedia\\\",\\n  \\\"action_input\\\": \\\"Prompt engineering\\\"\\n}\\n```\\n\"\n","}\n","```\n","\n","这里的内容和上面的是一致的。\n","\n","进入 `[1:chain:AgentExecutor > 4:tool:Wikipedia]` 输入下面内容：\n","\n","```\n","\"Prompt engineering\"\n","```\n","\n","疑问：为什么这里就进入 `tool:Wikipedia` 了？因为在经过了 `Thought` 之后，执行 `Action` 时就是调用该工具。\n","\n","退出 `[1:chain:AgentExecutor > 4:tool:Wikipedia]` 输出下面内容：\n","\n","```\n","\"Page: Prompt engineering\n","Summary: Prompt engineering is a concept in artificial intelligence, particularly natural language processing (NLP). In prompt engineering, the description of the task that the AI is supposed to accomplish is embedded in the input, e.g. as a question, instead of it being explicitly given. Prompt engineering typically works by converting one or more tasks to a prompt-based dataset and training a language model with what has been called \"prompt-based learning\" or just \"prompt learning\".\n","\n","Page: In-context learning (natural language processing)\n","Summary: In natural language processing, in-context learning, few-shot learning or few-shot prompting is a prompting technique that allows a model to process examples before attempting a task. The method was popularized after the advent of GPT-3 and is considered to be an emergent property of large language models when its scaling behavior contains greater than zero breaks.A few-shot prompt normally includes n examples of (problem, solution) pairs known as \"shots\", with the overall usage of such a prompt being known as n-shot prompting. For instance, the following is a one-shot prompt for review sentiment classification: Review: This movie sucks. Sentiment: negative. Review: I love this movie. Sentiment: If the model outputs \"positive\", then it has correctly solved the task.The term zero-shot prompting is often used to signify that no examples are provided. An example of a zero-shot prompt for a question-answering task would be \"Who wrote the book On the Origin of Species?\".\n","In-context learning was initially proposed as an alternative to fine-tuning a pre-trained language model on a task-specific dataset. Since no parameters are changed in the model, the model itself doesn't learn anything. But the prompt primes the model for subsequent inference, within a particular conversation or context.  The main advantages of in-context learning over fine-tuning are a reduction in the amount of task-specific data needed and a reduced potential of overfitting by learning an overly narrow distribution from a large but narrow fine-tuning dataset. Few-shot performance of large language models has been shown to achieve competitive results on NLP tasks, sometimes surpassing prior state-of-the-art fine-tuning approaches. Examples of such NLP tasks are translation, question answering, cloze tasks, unscrambling words, and using a novel word in a sentence. The creation and optimization of such few-shot prompts is part of the now active field of study of prompt engineering.While few-shot prompting has performed competitively when compared to fine-tuned models, it has its own drawbacks. For example, it has been shown that the order in which the shots are listed can make the difference between state-of-the-art and random guess performance. A set of few-shot examples that works well in some specific order with one model may not work at all when used with a different model. Despite these shortcomings, the commonly used Transformer model can encode principled learning algorithms based on gradient descent inside their weights and enable mesa-optimization i.e. learn-to-learn small models based on the data given in-context when making predictions.A common example of in-context learning is chain-of-thought prompting, where few-shot examples are given to teach the model to output a string of reasoning before attempting to answer a question. This technique has been shown to improve performance of models in tasks that require logical thinking and reasoning.\"\n","```\n","\n","疑问：`tool:Wikipedia` 做了什么？为什么就输出这堆内容？调用相关 API 然后将 `action_input` 作为参数发起请求，请求结果返回后进行格式化，最终输出这堆内容。\n","\n","可以看见输出的内容有俩部分，这并不能作为 `Final Answer`，我们实际上只需要第一部分（由于我们前面的 prompt 告诉了 gpt，需要它去判断 `Observation` 的结果是否可以用作用户的 `Question` 的答案，这里 gpt 也和我们的想法一致，`Action` 输出的内容是无法解决用户问题的，因为如果能解决的话就直接输出的 `Final Answer` 了）。\n","\n","```\n","Page: Prompt engineering\n","Summary: ...\n","\n","Page: In-context learning (natural language processing)\n","Summary: ...\n","```\n","\n","进入 `[1:chain:AgentExecutor > 5:chain:LLMChain]` 输入下面内容：\n","\n","```json\n","{\n","  \"input\": \"详细介绍 Prompt engineering\",\n","  \"agent_scratchpad\": \"This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nQuestion: Can you provide a detailed introduction to Prompt engineering?\\nThought: I'm not sure what Prompt engineering is, so I'll need to use Wikipedia ... 省略\n","  \"stop\": [\n","    \"Observation:\"\n","  ]\n","}\n","```\n","\n","这里通过 `agent_scratchpad` 携带了的中间结果（`Question -> Thought -> Action -> Observation`），并且在字符串首部插入了一段：\n","\n","```\n","This was your previous work (but I haven't seen any of it! I only see what you return as final answer)\n","```\n","\n","告知 gpt 之前的工作内容以及告诉它目前还没有得出 `Final Answer`。\n","\n","进入 `[1:chain:AgentExecutor > 5:chain:LLMChain > 6:llm:ChatOpenAI]` 输入下面内容：\n","\n","```json\n","{\n","  \"prompts\": [\n","    \"System: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \\\"action\\\" field are: Calculator, Wikipedia\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\\nHuman: 详细介绍 Prompt engineering\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nQuestion: Can you provide a detailed introduction to Prompt engineering?\\nThought: I'm not sure what Prompt engineering is, so I'll need to use Wikipedia to research it.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Wikipedia\\\",\\n  \\\"action_input\\\": \\\"Prompt engineering\\\"\\n}\\n```\\n\\nObservation: Page: Prompt engineering\\nSummary: Prompt engineering is a concept in artificial intelligence, particularly natural language processing (NLP). In prompt engineering, the description of the task that the AI is supposed to accomplish is embedded in the input, e.g. as a question, instead of it being explicitly given. Prompt engineering typically works by converting one or more tasks to a prompt-based dataset and training a language model with what has been called \\\"prompt-based learning\\\" or just \\\"prompt learning\\\".\\n\\nPage: In-context learning (natural language processing)\\nSummary: In natural language processing, in-context learning, few-shot learning or few-shot prompting is a prompting technique that allows a model to process examples before attempting a task. The method was popularized after the advent of GPT-3 and is considered to be an emergent property of large language models when its scaling behavior contains greater than zero breaks.A few-shot prompt normally includes n examples of (problem, solution) pairs known as \\\"shots\\\", with the overall usage of such a prompt being known as n-shot prompting. For instance, the following is a one-shot prompt for review sentiment classification: Review: This movie sucks. Sentiment: negative. Review: I love this movie. Sentiment: If the model outputs \\\"positive\\\", then it has correctly solved the task.The term zero-shot prompting is often used to signify that no examples are provided. An example of a zero-shot prompt for a question-answering task would be \\\"Who wrote the book On the Origin of Species?\\\".\\nIn-context learning was initially proposed as an alternative to fine-tuning a pre-trained language model on a task-specific dataset. Since no parameters are changed in the model, the model itself doesn't learn anything. But the prompt primes the model for subsequent inference, within a particular conversation or context.  The main advantages of in-context learning over fine-tuning are a reduction in the amount of task-specific data needed and a reduced potential of overfitting by learning an overly narrow distribution from a large but narrow fine-tuning dataset. Few-shot performance of large language models has been shown to achieve competitive results on NLP tasks, sometimes surpassing prior state-of-the-art fine-tuning approaches. Examples of such NLP tasks are translation, question answering, cloze tasks, unscrambling words, and using a novel word in a sentence. The creation and optimization of such few-shot prompts is part of the now active field of study of prompt engineering.While few-shot prompting has performed competitively when compared to fine-tuned models, it has its own drawbacks. For example, it has been shown that the order in which the shots are listed can make the difference between state-of-the-art and random guess performance. A set of few-shot examples that works well in some specific order with one model may not work at all when used with a different model. Despite these shortcomings, the commonly used Transformer model can encode principled learning algorithms based on gradient descent inside their weights and enable mesa-optimization i.e. learn-to-learn small models based on the data given in-context when making predictions.A common example of in-context learning is chain-of-thought prompting, where few-shot examples are given to teach the model to output a string of reasoning before attempting to answer a question. This technique has been shown to improve performance of models in tasks that require logical thinking and reasoning.\\nThought:\"\n","  ]\n","}\n","```\n","\n","该 prompt 做了下面几件事情：\n","\n","- 携带 System Prompt\n","- 在 `Human:` 后面除了携带用户输入的问题，还将之前的 `agent_scratchpad` 携带上了\n","- 继续让 gpt 进行 `Thought`，开启下一轮的 `Thought -> Action -> Observation`\n","\n","退出 `[1:chain:AgentExecutor > 5:chain:LLMChain > 6:llm:ChatOpenAI]`\n","\n"],"metadata":{"id":"9YyL04aRXxep"}},{"cell_type":"markdown","source":["## 使用 Agents 进行代码执行与推理"],"metadata":{"id":"vLI_OY-mfpNZ"}},{"cell_type":"code","source":["agent = create_python_agent(\n","    llm,\n","    tool=PythonREPLTool(),\n","    verbose=True\n",")"],"metadata":{"id":"Cb8iM_4Aigis"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["customer_list = [\n","    [\"Harrison\", \"Chase\"],\n","    [\"Lang\", \"Chain\"],\n","    [\"Dolly\", \"Too\"],\n","    [\"Elle\", \"Elem\"],\n","    [\"Geoff\",\"Fusion\"],\n","    [\"Trance\",\"Former\"],\n","    [\"Jen\",\"Ayai\"]\n","]\n","\n","agent.run(f\"\"\"Sort these customers by last name and then first name and print the output: {customer_list}\"\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":430},"id":"0qlRQQ07ikuA","executionInfo":{"status":"ok","timestamp":1687746800920,"user_tz":-480,"elapsed":16839,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}},"outputId":"49f8fbfe-589a-48b4-c899-dcd4f95d78cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new  chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mI can use the sorted() function to sort the list of customers by last name and then first name. I will need to provide a key function to sorted() that returns a tuple of the last name and first name in that order.\n","Action: Python_REPL\n","Action Input: \n","```\n","customers = [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\n","sorted(customers, key=lambda x: (x[1], x[0]))\n","```\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3mThe output is a sorted list of customers by last name and then first name.\n","Action: Python_REPL\n","Action Input: `print(sorted(customers, key=lambda x: (x[1], x[0])))`\u001b[0m\n","Observation: \u001b[36;1m\u001b[1;3m[['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\n","\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n","Final Answer: [['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\"[['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["## 自定义 Agents Tool"],"metadata":{"id":"aegzeyqe0zGO"}},{"cell_type":"markdown","source":["在前文中使用的都是 LangChain 提供的 tool，如果我们想在执行 agents 过程中调用自己的 api 或者使用自己的数据库，那么就需要自定义 tools 来实现。\n","\n","下面会自定义一个 tool，作用是告诉我们当前日期时间是什么。"],"metadata":{"id":"H4_2U7x10-LA"}},{"cell_type":"markdown","source":["首先，对仅使用了 `[\"llm-math\", \"wikipedia\"]` 的 agents 提问今天的日期。"],"metadata":{"id":"mTdkZhfl8FRN"}},{"cell_type":"code","source":["agent.run(\"What's the date today?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":590},"id":"29741WMJ48Si","executionInfo":{"status":"error","timestamp":1687753420969,"user_tz":-480,"elapsed":5043,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}},"outputId":"50d419bf-6ff3-4fb1-ce81-05b2706a0554"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new  chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mQuestion: What's the date today?\n","Thought: I can use the calculator tool to get the current date.\n","Action:\n","```\n","{\n","  \"action\": \"Calculator\",\n","  \"action_input\": \"today's date\"\n","}\n","```\n","\u001b[0m"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-a3beaea8526b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What's the date today?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, *args, **kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_output_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             outputs = (\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;31m# We now enter the agent loop (until it returns something).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_continue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m             next_step_output = self._take_next_step(\n\u001b[0m\u001b[1;32m    988\u001b[0m                 \u001b[0mname_to_tool_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m                 \u001b[0mcolor_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/agents/agent.py\u001b[0m in \u001b[0;36m_take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    848\u001b[0m                     \u001b[0mtool_run_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"llm_prefix\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;31m# We then call the tool on the tool input to get an observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m                 observation = tool.run(\n\u001b[0m\u001b[1;32m    851\u001b[0m                     \u001b[0magent_action\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/tools/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_tool_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             run_manager.on_tool_end(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/tools/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mtool_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_args_and_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             observation = (\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtool_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtool_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtool_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtool_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/tools/base.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, run_manager, *args, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0mnew_argument_supported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         return (\n\u001b[0;32m--> 414\u001b[0;31m             self.func(\n\u001b[0m\u001b[1;32m    415\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, *args, **kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_output_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             outputs = (\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm_math/base.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_run_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         )\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_llm_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_run_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     async def _acall(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm_math/base.py\u001b[0m in \u001b[0;36m_process_llm_result\u001b[0;34m(self, llm_output, run_manager)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Answer: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"unknown format from LLM: {llm_output}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: unknown format from LLM: Sorry, as an AI language model, I do not have access to real-time information. Therefore, I cannot provide today's date."]}]},{"cell_type":"markdown","source":["提示 `\"unknown format from LLM: Sorry, as an AI language model, I do not have access to real-time information. Therefore, I cannot provide today's date.\"`，目前的 agents 并不能获取今天的日期是多少。"],"metadata":{"id":"PcWnCWGq8dcd"}},{"cell_type":"markdown","source":["下面实现一个 `date_time` agents tool。"],"metadata":{"id":"RpOnMroX8v3y"}},{"cell_type":"code","source":["!pip install DateTime"],"metadata":{"id":"nMe_wQRb2ErB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain.agents import tool\n","from datetime import date\n","\n","# 注意在函数里面必须使用首行注释，通过自然语言描述该 tool 的作用、参数以及返回值\n","# 这里的 @tool 装饰器的作用就是提取首行注释\n","@tool\n","def date_today(text: str) -> str:\n","    \"\"\"Returns todays date, use this for any \\\n","    questions related to knowing todays date. \\\n","    The input should always be an empty string, \\\n","    and this function will always return todays \\\n","    date.\"\"\"\n","    return str(date.today())"],"metadata":{"id":"RI8GEBJA2L7F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tools = load_tools([\"llm-math\", \"wikipedia\"], llm=llm)\n","# 将 date tool 添加到 tools 里面\n","tools.append(date_today)\n","\n","print(tools[0])\n","print(tools[-1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VmCMR7AOAPtf","executionInfo":{"status":"ok","timestamp":1687850603436,"user_tz":-480,"elapsed":5,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}},"outputId":"e9202b01-c2a8-49d0-f2b5-bf4b999ff10c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["name='Calculator' description='Useful for when you need to answer questions about math.' args_schema=None return_direct=False verbose=False callbacks=None callback_manager=None handle_tool_error=False func=<bound method Chain.run of LLMMathChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=NoOpOutputParser(), return_final_only=True, llm_kwargs={}), llm=None, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n', template_format='f-string', validate_template=True), input_key='question', output_key='answer')> coroutine=<bound method Chain.arun of LLMMathChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, llm_chain=LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n', template_format='f-string', validate_template=True), llm=ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), output_key='text', output_parser=NoOpOutputParser(), return_final_only=True, llm_kwargs={}), llm=None, prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n', template_format='f-string', validate_template=True), input_key='question', output_key='answer')>\n","name='date_today' description='date_today(text: str) -> str - Returns todays date, use this for any     questions related to knowing todays date.     The input should always be an empty string,     and this function will always return todays     date.' args_schema=<class 'pydantic.main.date_todaySchemaSchema'> return_direct=False verbose=False callbacks=None callback_manager=None handle_tool_error=False func=<function date_today at 0x7f8910d96440> coroutine=None\n"]}]},{"cell_type":"code","source":["agent = initialize_agent(\n","    tools,\n","    llm,\n","    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n","    handle_parsing_errors=True,\n","    verbose = True\n",")"],"metadata":{"id":"ajHS12Y88ai0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["agent.run(\"What's the date today?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":393},"id":"Tzb1cx7aAIUc","executionInfo":{"status":"ok","timestamp":1687754808676,"user_tz":-480,"elapsed":4894,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}},"outputId":"f1a56e68-695f-4039-b01b-1618ad965ffc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new  chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mThought: I can use the `date_today` tool to get today's date.\n","\n","Action:\n","```\n","{\n","  \"action\": \"date_today\",\n","  \"action_input\": \"\"\n","}\n","```\n","\n","\u001b[0m\n","Observation: \u001b[38;5;200m\u001b[1;3m2023-06-26\u001b[0m\n","Thought:\u001b[32;1m\u001b[1;3mI have successfully retrieved today's date using the `date_today` tool.\n","\n","Final Answer: Today's date is 2023-06-26.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\"Today's date is 2023-06-26.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":69}]}]}