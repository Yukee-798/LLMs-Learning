{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN7chYvFJ2I62KfGIyHTDC9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# LangChain: Memory"],"metadata":{"id":"eieRbR-sxsE1"}},{"cell_type":"markdown","source":["本节会介绍如何使用 LangChain 来让 ChatBot 记忆聊天上下文的内容。"],"metadata":{"id":"8wgB4SCaxvU3"}},{"cell_type":"markdown","source":["## 环境初始化"],"metadata":{"id":"Ri2TunELoEnK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pwKslj2GnEYv"},"outputs":[],"source":["!pip install python-dotenv\n","!pip install openai\n","!pip install --upgrade langchain"]},{"cell_type":"code","source":["%env OPENAI_API_KEY=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"],"metadata":{"id":"KXGeY47gt-bS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import openai\n","\n","from dotenv import load_dotenv, find_dotenv\n","_ = load_dotenv(find_dotenv()) # read local .env file\n","openai.api_key = os.environ['OPENAI_API_KEY']"],"metadata":{"id":"neioeItKuCPQ","executionInfo":{"status":"ok","timestamp":1687156484756,"user_tz":-480,"elapsed":4,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## ConversationBufferMemory"],"metadata":{"id":"xR76YiUJvJXN"}},{"cell_type":"markdown","source":["先说结论：\n","\n","- 语言模型本质上是不会记录和用户之间的对话的历史信息的，每次调用 API 发起的请求都是独立的；\n","- `ConversationBufferMemory` 的运作原理就是将 AI 与 Human 完整的对话记录存储在 buffer 中，Human 每次发起询问，都会自动携带上所有的历史对话记录；\n","- 随着对话变得越来越长，所需的记忆存储量也变得非常大，向 LLM 发生大量的 Token 的成本也会增加。\n"],"metadata":{"id":"NZYFiV_vyNZE"}},{"cell_type":"code","source":["from langchain.chat_models import ChatOpenAI\n","from langchain.chains import ConversationChain\n","from langchain.memory import ConversationBufferMemory"],"metadata":{"id":"ksiFq0LhvMLP","executionInfo":{"status":"ok","timestamp":1687156487063,"user_tz":-480,"elapsed":2311,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["这里的 `ConversionChain` 暂时不需要去知道原理，后面的章节会涉及。"],"metadata":{"id":"W6z1MVgf4fCu"}},{"cell_type":"code","source":["llm = ChatOpenAI(temperature=0.0)\n","memory = ConversationBufferMemory()\n","conversation = ConversationChain(\n","  llm=llm,\n","  memory=memory,\n","  verbose=True # 如果想知道 LangChain 的运行细节，则将 verbose 设置为 True\n",")"],"metadata":{"id":"VLH1zzvJvlqp","executionInfo":{"status":"ok","timestamp":1687156487063,"user_tz":-480,"elapsed":5,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["conversation.predict(input=\"Hi, my name is DwD\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"id":"sqKu2JWjwAQ5","executionInfo":{"status":"ok","timestamp":1687156489272,"user_tz":-480,"elapsed":2213,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}},"outputId":"4c8b27cb-8997-4ca5-91d0-ed87ca110915"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new  chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","\n","Human: Hi, my name is DwD\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\"Hello DwD, it's nice to meet you! My name is OpenAI. How can I assist you today?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["conversation.predict(input=\"What is 1+1?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":288},"id":"DFlRQHf5xRij","executionInfo":{"status":"ok","timestamp":1687156490417,"user_tz":-480,"elapsed":1152,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}},"outputId":"e2756512-32f0-4bb7-9b90-74de19785a11"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new  chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: Hi, my name is DwD\n","AI: Hello DwD, it's nice to meet you! My name is OpenAI. How can I assist you today?\n","Human: What is 1+1?\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["'The answer to 1+1 is 2.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["conversation.predict(input=\"What is my name?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":323},"id":"wjWxduqAxXv1","executionInfo":{"status":"ok","timestamp":1687156492463,"user_tz":-480,"elapsed":1689,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}},"outputId":"512c781b-1a6c-49ed-fdc5-ef3d040d1969"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new  chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: Hi, my name is DwD\n","AI: Hello DwD, it's nice to meet you! My name is OpenAI. How can I assist you today?\n","Human: What is 1+1?\n","AI: The answer to 1+1 is 2.\n","Human: What is my name?\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["'Your name is DwD, as you mentioned earlier.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["通过 `memory.buffer` 可以获取到当前所有的历史对话记录。"],"metadata":{"id":"5QrCJTwfy8VP"}},{"cell_type":"code","source":["print(memory.buffer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"100pCmZ6y7jV","executionInfo":{"status":"ok","timestamp":1687156492464,"user_tz":-480,"elapsed":14,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}},"outputId":"c7471d02-d563-4503-8b7d-fd1b8ec5bdc3"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Human: Hi, my name is DwD\n","AI: Hello DwD, it's nice to meet you! My name is OpenAI. How can I assist you today?\n","Human: What is 1+1?\n","AI: The answer to 1+1 is 2.\n","Human: What is my name?\n","AI: Your name is DwD, as you mentioned earlier.\n"]}]},{"cell_type":"markdown","source":["也可以使用下面的方式来获取历史对话记录："],"metadata":{"id":"Ol_e9B-AzYjl"}},{"cell_type":"code","source":["memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k5MSKKiBze68","executionInfo":{"status":"ok","timestamp":1687156492464,"user_tz":-480,"elapsed":10,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}},"outputId":"f5a6cc46-fa43-4e74-8335-2b0695d661b2"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': \"Human: Hi, my name is DwD\\nAI: Hello DwD, it's nice to meet you! My name is OpenAI. How can I assist you today?\\nHuman: What is 1+1?\\nAI: The answer to 1+1 is 2.\\nHuman: What is my name?\\nAI: Your name is DwD, as you mentioned earlier.\"}"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["调用 `load_memory_variables` 时，这里传入了一个空的字典，使用该函数可以做一些更高级的定制化配置，本节不会涉及相关内容。"],"metadata":{"id":"z_GpcFgC0jaw"}},{"cell_type":"markdown","source":["通过对话的方式将上下文写入 memory 外，也可以直接手动写入（往 buffer 中进行 append 的方式）："],"metadata":{"id":"RUySrsHA1aX_"}},{"cell_type":"code","source":["memory.save_context(\n","  {\"input\": \"How's the weather today?\"},\n","  {\"output\": \"Today is a sunny day.\"}\n",")\n","\n","print(memory.buffer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k2xb2Raf1luf","executionInfo":{"status":"ok","timestamp":1687156492464,"user_tz":-480,"elapsed":9,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}},"outputId":"f55b1ddf-5d17-41c4-b6de-afa817ef2f35"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Human: Hi, my name is DwD\n","AI: Hello DwD, it's nice to meet you! My name is OpenAI. How can I assist you today?\n","Human: What is 1+1?\n","AI: The answer to 1+1 is 2.\n","Human: What is my name?\n","AI: Your name is DwD, as you mentioned earlier.\n","Human: How's the weather today?\n","AI: Today is a sunny day.\n"]}]},{"cell_type":"markdown","source":["## ConversationBufferWindowMemory"],"metadata":{"id":"WMcr9zCF37FG"}},{"cell_type":"markdown","source":["作用：从命名来看，多了一个 `window`，因此就有了容量限制，`ConversationBufferWindowMemory` 会仅保留最后若干轮对话消息，这样可以防止历史记录无限增加。"],"metadata":{"id":"q7yiDAlR4Ccu"}},{"cell_type":"code","source":["from langchain.memory import ConversationBufferWindowMemory"],"metadata":{"id":"0ovoS4it3829","executionInfo":{"status":"ok","timestamp":1687156492464,"user_tz":-480,"elapsed":8,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["llm = ChatOpenAI(temperature=0.0)\n","memory = ConversationBufferWindowMemory(k=1) # 通过参数 k 来设置窗口大小，这里表示仅保留最后一轮对话记录\n","conversation = ConversationChain(\n","  llm=llm,\n","  memory=memory,\n","  verbose=True # 如果想知道 LangChain 的运行细节，则将 verbose 设置为 True\n",")"],"metadata":{"id":"CFx7D3QU4xvh","executionInfo":{"status":"ok","timestamp":1687156492464,"user_tz":-480,"elapsed":8,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["memory.save_context(\n","  {\"input\": \"How's the weather today?\"},\n","  {\"output\": \"Today is a sunny day.\"}\n",")\n","memory.save_context(\n","  {\"input\": \"My name is DwD.\"},\n","  {\"output\": \"Nice to meet you!\"}\n",")\n","\n","memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IdLsMtb25ItS","executionInfo":{"status":"ok","timestamp":1687156492465,"user_tz":-480,"elapsed":9,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}},"outputId":"4c63eace-df64-4f9f-b2a8-a10d31e4d300"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': 'Human: My name is DwD.\\nAI: Nice to meet you!'}"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["可以看到虽然写入了俩段对话，但是 memory 中仅保存了一段记录。"],"metadata":{"id":"4tX1yqSz56kw"}},{"cell_type":"markdown","source":["## ConversationTokenBufferMemory"],"metadata":{"id":"rUVQvhCd6yPP"}},{"cell_type":"markdown","source":["作用：因为大部分 LLMs 的 API 都是通过 token 计费，使用 `ConversationTokenBufferMemory` 可以将 memory 以 token 级别限制历史记录长度，比如 50 则会保留最新的长度为 50 个 token 的历史记录（不一定是 50 token，只需要保证低于 50 token）。"],"metadata":{"id":"uBkn9lKQ8WzV"}},{"cell_type":"markdown","source":["注意这里要安装一个新的依赖项。"],"metadata":{"id":"OhC5Z4vPAbFB"}},{"cell_type":"code","source":["!pip install tiktoken"],"metadata":{"id":"OtOrfmyAATNN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687156503450,"user_tz":-480,"elapsed":10992,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}},"outputId":"53e65f39-5e8f-4628-e8be-49a67486c7fb"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tiktoken\n","  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.27.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n","Installing collected packages: tiktoken\n","Successfully installed tiktoken-0.4.0\n"]}]},{"cell_type":"code","source":["from langchain.memory import ConversationTokenBufferMemory"],"metadata":{"id":"_bjlgwXG-8f4","executionInfo":{"status":"ok","timestamp":1687156503450,"user_tz":-480,"elapsed":6,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["这里有一个 llm 参数，因为不同的 LLM 对于 token 数量的计算方式不同。"],"metadata":{"id":"OXGKw6snBDWB"}},{"cell_type":"code","source":["llm = ChatOpenAI(temperature=0.0)\n","memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n","conversation = ConversationChain(\n","  llm=llm,\n","  memory=memory,\n","  verbose=True # 如果想知道 LangChain 的运行细节，则将 verbose 设置为 True\n",")"],"metadata":{"id":"ECws3vQz-4HU","executionInfo":{"status":"ok","timestamp":1687156503450,"user_tz":-480,"elapsed":5,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["memory.save_context(\n","  {\"input\": \"How's the weather today?\"},\n","  {\"output\": \"Today is a sunny day.\"}\n",")\n","memory.save_context(\n","  {\"input\": \"My name is DwD.\"},\n","  {\"output\": \"Nice to meet you!\"}\n",")\n","\n","memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SZyJhuAu_D0L","executionInfo":{"status":"ok","timestamp":1687156504779,"user_tz":-480,"elapsed":1334,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}},"outputId":"6b29c16d-7829-45e9-9b76-a381f298719f"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': 'Human: My name is DwD.\\nAI: Nice to meet you!'}"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["## ConversationSummaryBufferMemory"],"metadata":{"id":"CM_WfghQ6zOk"}},{"cell_type":"markdown","source":["作用：用第三人称视角总结当前历史对话记录，并且生成的 prompt 长度不能超过指定的 max_token。"],"metadata":{"id":"HkKL4y0tbc7I"}},{"cell_type":"code","source":["from langchain.memory import ConversationSummaryBufferMemory"],"metadata":{"id":"0iyNLsDCXwK-","executionInfo":{"status":"ok","timestamp":1687156633947,"user_tz":-480,"elapsed":362,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# create a long string\n","schedule = \"There is a meeting at 8am with your product team. \\\n","You will need your powerpoint presentation prepared. \\\n","9am-12pm have time to work on your LangChain \\\n","project which will go quickly because Langchain is such a powerful tool. \\\n","At Noon, lunch at the italian resturant with a customer who is driving \\\n","from over an hour away to meet you to understand the latest in AI. \\\n","Be sure to bring your laptop to show the latest LLM demo.\"\n","\n","memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n","memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n","memory.save_context({\"input\": \"Not much, just hanging\"}, {\"output\": \"Cool\"})\n","memory.save_context({\"input\": \"What is on the schedule today?\"}, {\"output\": f\"{schedule}\"})"],"metadata":{"id":"fizl7pvvakZx","executionInfo":{"status":"ok","timestamp":1687157783149,"user_tz":-480,"elapsed":3503,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["memory.load_memory_variables({})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_0NkqsTcMmP","executionInfo":{"status":"ok","timestamp":1687157793875,"user_tz":-480,"elapsed":538,"user":{"displayName":"kee Yu","userId":"15908361828736827251"}},"outputId":"8420020e-0c2d-402e-82c9-760c04bca532"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'history': \"System: The human and AI engage in small talk before discussing the day's schedule. The AI informs the human of a morning meeting with the product team, time to work on the LangChain project, and a lunch meeting with a customer interested in the latest AI developments.\"}"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["## Vector data memory"],"metadata":{"id":"UYYkMk6NdTEi"}},{"cell_type":"markdown","source":["## Entity memories"],"metadata":{"id":"wZBN-MY0dtZf"}}]}